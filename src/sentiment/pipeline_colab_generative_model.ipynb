{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n783BnV96D1Q"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"YOUR-SECRET-TOKEN\")"
      ],
      "metadata": {
        "id": "w-y6MBYJ-peA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dSsukIO06LRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.7\n",
        ")\n"
      ],
      "metadata": {
        "id": "wpOliWH4E_lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)"
      ],
      "metadata": {
        "id": "57hZHHdl6TYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # carica cluster_descriptions.json e theme_daily_sentiment.json\n"
      ],
      "metadata": {
        "id": "wqJN0WCM_wpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # carica  theme_daily_sentiment.json\n"
      ],
      "metadata": {
        "id": "KW-jWc16EVfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # carica  cluster_entity.json"
      ],
      "metadata": {
        "id": "KtqpT8gVPLx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"cluster_descriptions.json\", \"r\") as f:\n",
        "    cluster_labels = json.load(f)\n",
        "\n",
        "with open(\"theme_daily_sentiment.json\", \"r\") as f:\n",
        "    daily_sentiment = json.load(f)\n",
        "\n",
        "with open(\"cluster_entity_likes.json\", \"r\") as f:\n",
        "    entity_likes = json.load(f)\n"
      ],
      "metadata": {
        "id": "HFjiVn6U_1Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain.prompts import PromptTemplate\n",
        "from collections import defaultdict\n",
        "\n",
        "# === Carica i file JSON ===\n",
        "with open(\"cluster_descriptions.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    cluster_labels = json.load(f)\n",
        "\n",
        "with open(\"theme_daily_sentiment.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    daily_sentiment = json.load(f)\n",
        "\n",
        "with open(\"cluster_entity_likes.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    entity_likes_by_cluster = json.load(f)\n",
        "\n",
        "# === Organizza i dati giornalieri per cluster ===\n",
        "sentiment_by_cluster = defaultdict(list)\n",
        "for entry in daily_sentiment:\n",
        "    sentiment_by_cluster[str(entry[\"theme_cluster\"])].append(entry)\n",
        "\n",
        "# === Prompt template compatto ===\n",
        "cluster_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a social media analyst for the Monaco GP 2025.\n",
        "\n",
        "Topic: {topic_label}\n",
        "\n",
        "Recent sentiment trend:\n",
        "{daily_scores}\n",
        "\n",
        "Most mentioned entities (by total likes):\n",
        "{entity_likes}\n",
        "\n",
        "Write 2-3 sentences summarizing how the sentiment evolved over time.\n",
        "Then, comment on which drivers or teams got the most attention.\n",
        "Do not invent events or motivations.\n",
        "Use only the data provided above.\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# === Parametri di sicurezza ===\n",
        "\n",
        "cluster_id = \"2\"\n",
        "max_days = 5\n",
        "max_entities = 3\n",
        "\n",
        "# === Dati del cluster ===\n",
        "label = cluster_labels[cluster_id]\n",
        "trend = sorted(sentiment_by_cluster[cluster_id], key=lambda x: x[\"date\"])[-max_days:]\n",
        "daily_scores = \"\\n\".join(\n",
        "    f\"- {d['date']}: sentiment {d['avg_roberta_pos']:.2f}\" for d in trend\n",
        ")\n",
        "\n",
        "# === Entità più menzionate (con like) ===\n",
        "entity_likes = entity_likes_by_cluster.get(cluster_id, {})\n",
        "if entity_likes:\n",
        "    sorted_entities = sorted(entity_likes.items(), key=lambda x: x[1], reverse=True)[:max_entities]\n",
        "    entity_likes_str = \"\\n\".join(f\"- {name}: {likes} likes\" for name, likes in sorted_entities)\n",
        "else:\n",
        "    entity_likes_str = \"No major entities mentioned.\"\n",
        "\n",
        "# === Costruisci il prompt finale\n",
        "prompt = cluster_prompt.format(\n",
        "    topic_label=label,\n",
        "    daily_scores=daily_scores,\n",
        "    entity_likes=entity_likes_str\n",
        ")\n",
        "\n",
        "# === Genera output con pipeline Hugging Face\n",
        "result = generator(prompt)[0][\"generated_text\"]\n",
        "\n",
        "# === Stampa\n",
        "print(f\"\\n {label}\\n{result.strip()}\")\n"
      ],
      "metadata": {
        "id": "Ji-lf7hx_4DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}